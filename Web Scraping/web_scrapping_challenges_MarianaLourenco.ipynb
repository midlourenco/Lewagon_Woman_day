{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping â€” Try it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries and parsing the front page of the [Books To Scrape](http://books.toscrape.com/index.html) website.\n",
    "\n",
    "Every paragraph in this document is a *cell*, that can contain other text description, or a snipper of runnable Python code. \n",
    "\n",
    "To run the cell, select it and click \"Run\" in the toolbar, or just press `Shift-Enter`. Double-clicking the cell allows you to edit its contents.\n",
    "\n",
    "**Pro tip** ðŸ¤“:  Run your cells often to catch possible errors early! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://books.toscrape.com/index.html\"\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "scraped = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After **running** a cell above, you'll be able to use the `scraped` variable to look for elements on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>All products</h1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to see how:\n",
    "\n",
    "scraped.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ˜² If you feel lost, you can refresh your knowledge on the Learn platform inside \"Takeaways\" section and in lecture slides!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Print the title of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print output in Python, you can use the `print()` function. It can either take a literal value as an argument (`print(\"hello\")`, `print(2)`), or a variable â€” in that case the function will print the value that the variable refers to! \n",
    "\n",
    "```python\n",
    "name = \"Bob\"\n",
    "print(name) # => Bob\n",
    "```\n",
    "\n",
    "Remember you need to print just the _text_ inside the `<title>` tag, not the whole element!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All products | Books to Scrape - Sandbox\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "page_title=scraped.title.text.strip()\n",
    "print(page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ðŸ¤«</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "title_text = scraped.title.text.strip()\n",
    "print(title_text)\n",
    "</pre>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Print the *full* title of the first book on a page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how to locate a single element with BeautifulSoup. If lost, revisit the slides on the Learn platform, or visit the \"Takeaways\" section for a quick recap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "#first_book=scraped.article.h3.a.text  <-#we don't get full title but the title with \"...\"\n",
    "first_book=scraped.article.h3.a[\"title\"]\n",
    "print(first_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ðŸ¤«</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "title = scraped.article.h3.a[\"title\"]\n",
    "print(title)\n",
    "</pre>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Print *all* the full titles from the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Beautiful Soup methods that return a _collection_ of elements. Remind yourself of how to **loop** over them (`for.. in..` construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "all_items= scraped.find_all(\"article\", class_=\"product_pod\") # or instead class, we could use the condition: \"title=True\"\n",
    "for each in all_items:\n",
    "    print(each.h3.a[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Light in the Attic', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History of Humankind', 'The Requiem Red', 'The Dirty Little Secrets of Getting Your Dream Job', 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'The Black Maria', 'Starving Hearts (Triangular Trade Trilogy, #1)', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 'Rip it Up and Start Again', 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 'Olio', 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n"
     ]
    }
   ],
   "source": [
    "#alternative: if instead just print the result, we want to save the result in same variable. we can use a list:\n",
    "all_items= scraped.find_all(\"article\", class_=\"product_pod\") # or instead class, we could use the condition: \"title=True\"\n",
    "collection=[]\n",
    "for each in all_items:\n",
    "    collection.append(each.h3.a[\"title\"])\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ðŸ¤«</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "links = scraped.find_all(\"a\", title=True)\n",
    "for link in links:\n",
    "    print(link[\"title\"])\n",
    "</pre>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Print all the *prices* from the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can get rid of a currency symbol and convert text to a numerical value (given that the inital text value is in a variable called `price`):\n",
    "\n",
    "`price = float(price.text.lstrip(\"Â£\"))`\n",
    "\n",
    "You can use a **CSS class selector** for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.77, 53.74, 50.1, 47.82, 54.23, 22.65, 33.34, 17.93, 22.6, 52.15, 13.99, 20.66, 17.46, 52.29, 35.02, 57.25, 23.88, 37.59, 51.33, 45.17]\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "all_prices_color=scraped.select(\".price_color\")\n",
    "#print(all_prices)\n",
    "list_all_prices=[]\n",
    "for each in all_prices_color:\n",
    "    #print(float(each.text.lstrip(\"Â£\"))) #<- if we just want to print the prices\n",
    "    list_all_prices.append(float(each.text.lstrip(\"Â£\"))) # <-if we want to save all the prices in a list (maybe to use/check latter)\n",
    "print(list_all_prices) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ðŸ¤«</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "prices = scraped.select(\".price_color\")\n",
    "for price in prices:\n",
    "    price = float(price.text.lstrip(\"Â£\"))\n",
    "    print(price)\n",
    "</pre>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Get a corresponding price for each title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the resulting data structure should look like (a List of Dictionaries):\n",
    "\n",
    "```\n",
    "[{'Sharp Objects': 'WICKED above her hipbone, GIRL across her heart...'}, {'Sapiens: A Brief History of Humankind': 'From a renowned historian comes a groundbreaking narrative of humanityâ€™s ...}]\n",
    "```\n",
    "\n",
    "Note that the real descriptions will be much longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder on how you can append a Dictionary into an List:\n",
    "\n",
    "```python\n",
    "title_prices = []\n",
    "\n",
    "# Iterate over all articles \n",
    "    # Get article's title as `title` \n",
    "    # Get article's price as `price`\n",
    "    title_prices.append({title: price})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'A Light in the Attic': 51.77}, {'Tipping the Velvet': 53.74}, {'Soumission': 50.1}, {'Sharp Objects': 47.82}, {'Sapiens: A Brief History of Humankind': 54.23}, {'The Requiem Red': 22.65}, {'The Dirty Little Secrets of Getting Your Dream Job': 33.34}, {'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull': 17.93}, {'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics': 22.6}, {'The Black Maria': 52.15}, {'Starving Hearts (Triangular Trade Trilogy, #1)': 13.99}, {\"Shakespeare's Sonnets\": 20.66}, {'Set Me Free': 17.46}, {\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\": 52.29}, {'Rip it Up and Start Again': 35.02}, {'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991': 57.25}, {'Olio': 23.88}, {'Mesaerion: The Best Science Fiction Stories 1800-1849': 37.59}, {'Libertarianism for Beginners': 51.33}, {\"It's Only the Himalayas\": 45.17}]\n"
     ]
    }
   ],
   "source": [
    "title_prices = []\n",
    "\n",
    "# write your code here\n",
    "title_price_info=scraped.select(\".product_pod\")\n",
    "for each in title_price_info:\n",
    "    price_currency=each.find(\"p\", class_=\"price_color\")\n",
    "    price=float(price_currency.text.lstrip(\"Â£\"))\n",
    "    title=each.h3.a[\"title\"]\n",
    "    title_prices.append({title: price})\n",
    "\n",
    "#print(title_price_info)\n",
    "print(title_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <strong>Reveal answer ðŸ¤«</strong>\n",
    "</summary>\n",
    "<pre>\n",
    "title_prices = []\n",
    "\n",
    "articles = scraped.select(\".product_pod\")\n",
    "\n",
    "for article in articles:\n",
    "    title = article.h3.a[\"title\"]\n",
    "    price = article.find(\"p\", class_=\"price_color\")\n",
    "    price_float = float(price.text.lstrip(\"Â£\"))\n",
    "    title_prices.append({title: price_float}) # Create a Dictionary and append to Array\n",
    "    \n",
    "print(title_prices)\n",
    "</pre>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can click on \"Save to browser storage\" icon next to \"Download\" on top of this notebook. Next time you connect to MyBinder you can restore your work by clicking \"Restore from browser storage\". \n",
    "\n",
    "Take as much time as you need to build a scraper for any website that you want! Keep in mind the information you are trying to scrape should be in public access and not protected by login/password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for a complete scraper when you feel like it :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
